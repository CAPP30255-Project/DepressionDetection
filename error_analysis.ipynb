{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "error_analysis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNCR6ya5OiSP5ymHfZ+hKGC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CAPP30255-Project/DepressionDetection/blob/master/error_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7KIz0RICifI",
        "outputId": "430327c6-6f55-4f3e-d5ec-f7a795c712b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from google.colab import drive\n",
        "ROOT = '/content/drive'\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from os.path import join \n",
        "repo_dir = '/content/drive/MyDrive/Repos/DepressionDetection'"
      ],
      "metadata": {
        "id": "ts97LvEhEPde"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = repo_dir + '/data/Suicide_Detection.csv'\n"
      ],
      "metadata": {
        "id": "_8IHIwKRESyi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"{repo_dir}\"\n",
        "#%pip install -r jj_dt_project_requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLghMPfaET-8",
        "outputId": "0a2b3959-3581-427a-dace-d2ff52689e77"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Repos/DepressionDetection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install torchtext==0.12.0"
      ],
      "metadata": {
        "id": "ESqbcGXpEV4M"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from data.data_process import *\n",
        "from _core.bow_classifier import *\n",
        "from _core.cnn_model import *"
      ],
      "metadata": {
        "id": "qry40Oq3Enog"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Best Model (Glove Split)"
      ],
      "metadata": {
        "id": "hKFYxAKfMOQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "depression_data = dep_data(data_dir, tokenizer = \"split\")\n",
        "depression_data.split_data(123)\n",
        "\n",
        "from torchtext import vocab\n",
        "\n",
        "glove = vocab.GloVe('6B')\n",
        "\n",
        "def bow_classifier2(data):\n",
        "    counter = Counter()\n",
        "    for (line, label) in data:\n",
        "        counter.update(line)\n",
        "    vocab = v(counter, specials = ['<unk>'], special_first = True, min_freq = 1000)\n",
        "    return vocab, counter\n",
        "\n",
        "from torchtext.vocab import vocab as v\n",
        "vocab_words, counter = bow_classifier2(depression_data.all_data)\n",
        "vocab_words.set_default_index(0)\n",
        "glove_vector = glove.get_vecs_by_tokens(vocab_words.get_itos())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaRRDiYEGJsT",
        "outputId": "a381d5d8-9bf7-4eed-dcd6-e3422a8fa08e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  result = getattr(asarray(obj), method)(*args, **kwds)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    vectors = torch.zeros(len(batch), len(vocab_words))\n",
        "    label_mapping = {'non-suicide': 0, 'suicide': 1}\n",
        "    labels = []\n",
        "    for index, example in enumerate(batch):\n",
        "      indexes = vocab_words(example[0])\n",
        "      for w_idx in indexes:\n",
        "        vectors[index, int(w_idx)] = 1\n",
        "      labels.append(label_mapping.get(example[1]))\n",
        "    labels = torch.tensor(labels)\n",
        "    return   labels.cuda(), vectors.cuda()\n"
      ],
      "metadata": {
        "id": "Ipyra9_IGQ8a"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BEST_PATH_LOGISTIC = \"output/logistic_glove_split_best.pt\"\n",
        "with open(BEST_PATH_LOGISTIC, 'rb') as f:\n",
        "    logistic = torch.load(f)"
      ],
      "metadata": {
        "id": "O3yteRuWHS3o"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "test_dataloader = DataLoader(depression_data.test, batch_size=BATCH_SIZE,\n",
        "                             shuffle=False, \n",
        "                             collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "RAL61GzAGTVz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_probs = []\n",
        "all_labels = []\n",
        "for b, (label, text) in enumerate(test_dataloader):\n",
        "    log_probs = logistic(text)\n",
        "    _, preds = torch.max(log_probs, 1)\n",
        "    for pred in preds.tolist():\n",
        "      all_probs.append(pred)\n",
        "    for l in label.tolist():\n",
        "      all_labels.append(l)\n",
        "    if b > 4:\n",
        "      break\n",
        "index = list(np.array(all_probs) != np.array(all_labels))"
      ],
      "metadata": {
        "id": "Pyxbqg4sGUvl"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wrong_preds = []\n",
        "reverse_map = {'suicide': 'non-suicide', 'non-suicide': 'suicide'}\n",
        "for (i, result) in enumerate(index):\n",
        "  if result:\n",
        "    wrong_preds.append(\n",
        "        {'text' : ' '.join(\n",
        "            depression_data.test[i][0]),\n",
        "        'true_label' : \n",
        "         depression_data.test[i][1],\n",
        "         'algorithm_label': reverse_map.get(depression_data.test[i][1])})"
      ],
      "metadata": {
        "id": "ghJuUO6oIddO"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(wrong_preds).to_csv('output/logistic_glove_split_best_errors.csv', index = False)"
      ],
      "metadata": {
        "id": "RvZInUazJh_y"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN Best Model (GloVe NLTK)"
      ],
      "metadata": {
        "id": "oN2V8Np7Noz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "si44jhUlKBkW",
        "outputId": "84be247b-6046-4e6a-d05d-8a8a8c9fcbfe"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "depression_data = dep_data(data_dir, tokenizer = \"NLTK\")"
      ],
      "metadata": {
        "id": "iZjvdmkFN6A9"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "depression_data.split_data(123)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vZuhcrHN871",
        "outputId": "ddfc8cef-154f-477a-f8eb-444b992632fd"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  result = getattr(asarray(obj), method)(*args, **kwds)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "id": "N-aHys9bOC9N"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext import vocab\n",
        "\n",
        "glove = vocab.GloVe('6B')\n",
        "\n",
        "def bow_classifier2(data):\n",
        "    counter = Counter()\n",
        "    for (line, label) in data:\n",
        "        counter.update(line)\n",
        "    vocab = v(counter, specials = ['<unk>'], special_first = True, min_freq = 1000)\n",
        "    return vocab, counter\n",
        "\n",
        "from torchtext.vocab import vocab as v\n",
        "vocab_words, counter = bow_classifier2(depression_data.all_data)\n",
        "vocab_words.set_default_index(0)\n",
        "glove_vector = glove.get_vecs_by_tokens(vocab_words.get_itos())"
      ],
      "metadata": {
        "id": "x_mq2VBtOE4i"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    vectors = torch.zeros(len(batch), len(vocab_words))\n",
        "    label_mapping = {'non-suicide': 0, 'suicide': 1}\n",
        "    labels = []\n",
        "    for index, example in enumerate(batch):\n",
        "      indexes = vocab_words(example[0])\n",
        "      for w_idx in indexes:\n",
        "        vectors[index, int(w_idx)] = 1\n",
        "      labels.append(label_mapping.get(example[1]))\n",
        "    labels = torch.tensor(labels)\n",
        "    return  vectors.cuda(), labels.cuda()"
      ],
      "metadata": {
        "id": "q40-iLrdOGsz"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataloader = DataLoader(depression_data.test, batch_size=BATCH_SIZE,\n",
        "                             shuffle=False, \n",
        "                             collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "Dd6aSfcGOH_R"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BEST_PATH_CNN = \"output/CNN_glove_nltk_best.pt\"\n",
        "with open(BEST_PATH_CNN, 'rb') as f:\n",
        "    cnn = torch.load(f)"
      ],
      "metadata": {
        "id": "mAJ5a89VOI_U"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_probs = []\n",
        "all_labels = []\n",
        "for b, (text, label) in enumerate(test_dataloader):\n",
        "    log_probs = cnn(text)\n",
        "    _, preds = torch.max(log_probs, 1)\n",
        "    for pred in preds.tolist():\n",
        "      all_probs.append(pred)\n",
        "    for l in label.tolist():\n",
        "      all_labels.append(l)\n",
        "    if b > 4:\n",
        "      break\n",
        "index = list(np.array(all_probs) != np.array(all_labels))"
      ],
      "metadata": {
        "id": "xfBDsvVAOVc_"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wrong_preds = []\n",
        "reverse_map = {'suicide': 'non-suicide', 'non-suicide': 'suicide'}\n",
        "for (i, result) in enumerate(index):\n",
        "  if result:\n",
        "    wrong_preds.append(\n",
        "        {'text' : ' '.join(\n",
        "            depression_data.test[i][0]),\n",
        "        'true_label' : \n",
        "         depression_data.test[i][1],\n",
        "         'algorithm_label': reverse_map.get(depression_data.test[i][1])})"
      ],
      "metadata": {
        "id": "QDoqGhuGPNws"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(wrong_preds).to_csv('output/cnn_glove_nltk_best_errors.csv', index = False)"
      ],
      "metadata": {
        "id": "FCIwg3exPUMp"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# bi-LSTM GloVe Split"
      ],
      "metadata": {
        "id": "VQ89zRNlPq0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "depression_data = dep_data(data_dir, tokenizer = \"split\")\n",
        "depression_data.split_data(123)\n",
        "\n",
        "from torchtext import vocab\n",
        "\n",
        "glove = vocab.GloVe('6B')\n",
        "\n",
        "def bow_classifier2(data):\n",
        "    counter = Counter()\n",
        "    for (line, label) in data:\n",
        "        counter.update(line)\n",
        "    vocab = v(counter, specials = ['<unk>'], special_first = True, min_freq = 1000)\n",
        "    return vocab, counter\n",
        "\n",
        "from torchtext.vocab import vocab as v\n",
        "vocab_words, counter = bow_classifier2(depression_data.all_data)\n",
        "vocab_words.set_default_index(0)\n",
        "glove_vector = glove.get_vecs_by_tokens(vocab_words.get_itos())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNM70WpkPkOw",
        "outputId": "a816fdc9-61e5-4bf2-ce92-5801f10c8d8f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  result = getattr(asarray(obj), method)(*args, **kwds)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    vectors = torch.zeros(len(batch), len(vocab_words))\n",
        "    label_mapping = {'non-suicide': 0, 'suicide': 1}\n",
        "    labels = []\n",
        "    for index, example in enumerate(batch):\n",
        "      indexes = vocab_words(example[0])\n",
        "      for w_idx in indexes:\n",
        "        vectors[index, int(w_idx)] = 1\n",
        "      labels.append(label_mapping.get(example[1]))\n",
        "    labels = torch.tensor(labels)\n",
        "    return   labels.cuda(), vectors.cuda()\n"
      ],
      "metadata": {
        "id": "DHSBix76P-Jl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install allennlp\n",
        "#!pip install --upgrade google-cloud-storage"
      ],
      "metadata": {
        "id": "GMDSwRm9QcFT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BEST_PATH_LSTM = \"output/biLSTM_glove_best.pt\"\n",
        "with open(BEST_PATH_LSTM, 'rb') as f:\n",
        "    lstm = torch.load(f)"
      ],
      "metadata": {
        "id": "zUB5kam-P_mM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataloader = DataLoader(depression_data.test, batch_size=BATCH_SIZE,\n",
        "                             shuffle=False, \n",
        "                             collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "6d_vZV1PQJqX"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_probs = []\n",
        "all_labels = []\n",
        "for b, (label, text) in enumerate(test_dataloader):\n",
        "    log_probs = lstm(text)\n",
        "    _, preds = torch.max(log_probs, 1)\n",
        "    for pred in preds.tolist():\n",
        "      all_probs.append(pred)\n",
        "    for l in label.tolist():\n",
        "      all_labels.append(l)\n",
        "    if b > 4:\n",
        "      break\n",
        "index = list(np.array(all_probs) != np.array(all_labels))"
      ],
      "metadata": {
        "id": "HCscXAvQRjQf"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wrong_preds = []\n",
        "reverse_map = {'suicide': 'non-suicide', 'non-suicide': 'suicide'}\n",
        "for (i, result) in enumerate(index):\n",
        "  if result:\n",
        "    wrong_preds.append(\n",
        "        {'text' : ' '.join(\n",
        "            depression_data.test[i][0]),\n",
        "        'true_label' : \n",
        "         depression_data.test[i][1],\n",
        "         'algorithm_label': reverse_map.get(depression_data.test[i][1])})"
      ],
      "metadata": {
        "id": "TYWdisBcRmAt"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(wrong_preds).to_csv('output/LSTM_glove_split_best_errors.csv', index = False)"
      ],
      "metadata": {
        "id": "nc-hzFZeRrim"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "H5CSrXKNRtWG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
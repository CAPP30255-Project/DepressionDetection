{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bi-LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyODOuL/ag/wPmLKpTS3UgOc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CAPP30255-Project/DepressionDetection/blob/master/bi_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4HYbaaZEhv4",
        "outputId": "ca4ab774-4fa5-4ddc-ec23-2a4ecd2e3fc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from google.colab import drive\n",
        "ROOT = '/content/drive'\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "from os.path import join \n",
        "repo_dir = '/content/drive/MyDrive/Repos/DepressionDetection'"
      ],
      "metadata": {
        "id": "tphGzQOeEkR6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = repo_dir + '/data/Suicide_Detection.csv'"
      ],
      "metadata": {
        "id": "4PCAusfPElV0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"{repo_dir}\"\n",
        "#%pip install -r jj_dt_project_requirements.txt\n",
        "#!pip install torchtext==0.12.0\n",
        "#!pip install allennlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5kzJGXkEou9",
        "outputId": "06d900d3-0864-47f7-8ccb-8cd9dc83d110"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Repos/DepressionDetection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install --upgrade google-cloud-storage\n",
        "#restrart after running this\n"
      ],
      "metadata": {
        "id": "tt89JWFlL30J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWketIDoJL4c",
        "outputId": "4f2be03c-4d6f-40d7-95c4-979d136e1430"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.vocab import vocab as v\n",
        "from data.data_process import *\n",
        "from _core.bow_classifier import *\n",
        "from _core.bi_LSTM import *"
      ],
      "metadata": {
        "id": "3qSmyxIdSvjZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using BoW Split"
      ],
      "metadata": {
        "id": "LlOFx0by7i-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "depression_data = dep_data(data_dir, tokenizer = \"split\")\n",
        "depression_data.split_data(123)\n"
      ],
      "metadata": {
        "id": "RFMD6DQGEtPq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1b0322b-d769-4dcb-f761-bf06eaf85947"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  result = getattr(asarray(obj), method)(*args, **kwds)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "using_GPU = True"
      ],
      "metadata": {
        "id": "FairCbk4YBl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab, counter = bow_classifier(depression_data.all_data)"
      ],
      "metadata": {
        "id": "KM5zugxyX6Zc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = data_loader_bow(depression_data.train, vocab, BATCH_SIZE, shuffle = False)\n",
        "test_dataloader = data_loader_bow(depression_data.test, vocab, BATCH_SIZE, shuffle = False)\n",
        "val_dataloader = data_loader_bow(depression_data.val, vocab, BATCH_SIZE, shuffle = False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIwG6ebjXUJ-",
        "outputId": "c376d3e1-dffb-489a-a540-a2d13199f0ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab Size =  2141\n",
            "Vocab Size =  2141\n",
            "Vocab Size =  2141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "EPOCHS = 10\n",
        "torch.cuda.empty_cache()\n",
        "model = RNNDepressionClassifier(vocab_size = 2142,\n",
        "                                    num_classes = 2, \n",
        "                                    embedding_dim = 300, \n",
        "                                    hidden_size = 100, \n",
        "                                    num_layers = 2)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_function = nn.NLLLoss()\n",
        "best_accuracy = 0\n",
        "if using_GPU:\n",
        "    model.cuda()\n",
        "    loss_function.to('cuda')\n",
        "accuracies=[]\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train_an_epoch(dataloader = train_dataloader,\n",
        "                    model = model,\n",
        "                    optimizer = optimizer, \n",
        "                    loss_fn=loss_function,\n",
        "                    using_GPU = using_GPU)\n",
        "    accuracy = get_accuracy(val_dataloader, model)\n",
        "    if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            with open(\"/content/drive/MyDrive/Repos/DepressionDetection/output/biLSTM_bow_split_best.pt\", 'wb') as f:\n",
        "                torch.save(model, f)\n",
        "                print(\"New best model saved!\")\n",
        "    \n",
        "    accuracies.append(accuracy)\n",
        "    print()\n",
        "    print(f'After epoch {epoch} the validation accuracy is {accuracy:.3f}.')\n",
        "    print()\n",
        "    \n",
        "plt.plot(range(1, EPOCHS+1), accuracies)\n"
      ],
      "metadata": {
        "id": "YbHhOz2CKSiy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b33a787f-8263-494a-f637-a0f38b113440"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "At iteration 200 the loss is 0.694.\n",
            "At iteration 400 the loss is 0.697.\n",
            "At iteration 600 the loss is 0.692.\n",
            "At iteration 800 the loss is 0.698.\n",
            "At iteration 1000 the loss is 0.693.\n",
            "At iteration 1200 the loss is 0.693.\n",
            "At iteration 1400 the loss is 0.694.\n",
            "At iteration 1600 the loss is 0.694.\n",
            "At iteration 1800 the loss is 0.694.\n",
            "At iteration 2000 the loss is 0.692.\n",
            "New best model saved!\n",
            "\n",
            "After epoch 1 the validation accuracy is 58.333.\n",
            "\n",
            "At iteration 200 the loss is 0.693.\n",
            "At iteration 400 the loss is 0.694.\n",
            "At iteration 600 the loss is 0.693.\n",
            "At iteration 800 the loss is 0.693.\n",
            "At iteration 1000 the loss is 0.693.\n",
            "At iteration 1200 the loss is 0.693.\n",
            "At iteration 1400 the loss is 0.694.\n",
            "At iteration 1600 the loss is 0.693.\n",
            "At iteration 1800 the loss is 0.693.\n",
            "At iteration 2000 the loss is 0.693.\n",
            "\n",
            "After epoch 2 the validation accuracy is 41.667.\n",
            "\n",
            "At iteration 200 the loss is 0.693.\n",
            "At iteration 400 the loss is 0.694.\n",
            "At iteration 600 the loss is 0.693.\n",
            "At iteration 800 the loss is 0.692.\n",
            "At iteration 1000 the loss is 0.693.\n",
            "At iteration 1200 the loss is 0.693.\n",
            "At iteration 1400 the loss is 0.694.\n",
            "At iteration 1600 the loss is 0.693.\n",
            "At iteration 1800 the loss is 0.693.\n",
            "At iteration 2000 the loss is 0.693.\n",
            "\n",
            "After epoch 3 the validation accuracy is 41.667.\n",
            "\n",
            "At iteration 200 the loss is 0.693.\n",
            "At iteration 400 the loss is 0.694.\n",
            "At iteration 600 the loss is 0.693.\n",
            "At iteration 800 the loss is 0.693.\n",
            "At iteration 1000 the loss is 0.693.\n",
            "At iteration 1200 the loss is 0.693.\n",
            "At iteration 1400 the loss is 0.694.\n",
            "At iteration 1600 the loss is 0.693.\n",
            "At iteration 1800 the loss is 0.693.\n",
            "At iteration 2000 the loss is 0.693.\n",
            "\n",
            "After epoch 4 the validation accuracy is 41.667.\n",
            "\n",
            "At iteration 200 the loss is 0.693.\n",
            "At iteration 400 the loss is 0.693.\n",
            "At iteration 600 the loss is 0.693.\n",
            "At iteration 800 the loss is 0.696.\n",
            "At iteration 1000 the loss is 0.693.\n",
            "At iteration 1200 the loss is 0.693.\n",
            "At iteration 1400 the loss is 0.694.\n",
            "At iteration 1600 the loss is 0.693.\n",
            "At iteration 1800 the loss is 0.693.\n",
            "At iteration 2000 the loss is 0.693.\n",
            "\n",
            "After epoch 5 the validation accuracy is 41.667.\n",
            "\n",
            "At iteration 200 the loss is 0.693.\n",
            "At iteration 400 the loss is 0.693.\n",
            "At iteration 600 the loss is 0.693.\n",
            "At iteration 800 the loss is 0.693.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using BoW NLTK"
      ],
      "metadata": {
        "id": "KYpVPIOC7llM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import nltk\n",
        "#nltk.download('punkt')"
      ],
      "metadata": {
        "id": "IfNKhzpsZvh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "depression_data = dep_data(data_dir, tokenizer = \"NLTK\")\n",
        "depression_data.split_data(123)\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "using_GPU = True\n",
        "EPOCHS = 5\n",
        "\n",
        "vocab, counter = bow_classifier(depression_data.all_data)\n",
        "train_dataloader = data_loader_bow(depression_data.train, vocab, BATCH_SIZE, shuffle = False)\n",
        "test_dataloader = data_loader_bow(depression_data.test, vocab, BATCH_SIZE, shuffle = False)\n",
        "val_dataloader = data_loader_bow(depression_data.val, vocab, BATCH_SIZE, shuffle = False)"
      ],
      "metadata": {
        "id": "ncLdGjfu7m3m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1bd13aa-c1a9-430f-96ed-4f937a4e0d53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  result = getattr(asarray(obj), method)(*args, **kwds)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab Size =  1930\n",
            "Vocab Size =  1930\n",
            "Vocab Size =  1930\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "EPOCHS = 10\n",
        "torch.cuda.empty_cache()\n",
        "model = RNNDepressionClassifier(vocab_size = 2142,\n",
        "                                    num_classes = 2, \n",
        "                                    embedding_dim = 300, \n",
        "                                    hidden_size = 100, \n",
        "                                    num_layers = 2)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_function = nn.NLLLoss()\n",
        "best_accuracy = 0\n",
        "if using_GPU:\n",
        "    model.cuda()\n",
        "    loss_function.to('cuda')\n",
        "accuracies=[]\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train_an_epoch(dataloader = train_dataloader,\n",
        "                    model = model,\n",
        "                    optimizer = optimizer, \n",
        "                    loss_fn=loss_function,\n",
        "                    using_GPU = using_GPU)\n",
        "    accuracy = get_accuracy(val_dataloader, model)\n",
        "    if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            with open(\"/content/drive/MyDrive/Repos/DepressionDetection/output/biLSTM_bow_NLTK_best.pt\", 'wb') as f:\n",
        "                torch.save(model, f)\n",
        "                print(\"New best model saved!\")\n",
        "    \n",
        "    accuracies.append(accuracy)\n",
        "    print()\n",
        "    print(f'After epoch {epoch} the validation accuracy is {accuracy:.3f}.')\n",
        "    print()\n",
        "    \n",
        "plt.plot(range(1, EPOCHS+1), accuracies)\n"
      ],
      "metadata": {
        "id": "7XPlbrCb7t3F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "996a023f-bece-45ca-97d2-ba6a36a68f1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "At iteration 200 the loss is 0.696.\n",
            "At iteration 400 the loss is 0.696.\n",
            "At iteration 600 the loss is 0.693.\n",
            "At iteration 800 the loss is 0.697.\n",
            "At iteration 1000 the loss is 0.693.\n",
            "At iteration 1200 the loss is 0.694.\n",
            "At iteration 1400 the loss is 0.694.\n",
            "At iteration 1600 the loss is 0.693.\n",
            "At iteration 1800 the loss is 0.692.\n",
            "At iteration 2000 the loss is 0.692.\n",
            "New best model saved!\n",
            "\n",
            "After epoch 1 the validation accuracy is 41.667.\n",
            "\n",
            "At iteration 200 the loss is 0.693.\n",
            "At iteration 400 the loss is 0.694.\n",
            "At iteration 600 the loss is 0.692.\n",
            "At iteration 800 the loss is 0.694.\n",
            "At iteration 1000 the loss is 0.693.\n",
            "At iteration 1200 the loss is 0.693.\n",
            "At iteration 1400 the loss is 0.693.\n",
            "At iteration 1600 the loss is 0.693.\n",
            "At iteration 1800 the loss is 0.693.\n",
            "At iteration 2000 the loss is 0.693.\n",
            "\n",
            "After epoch 2 the validation accuracy is 41.667.\n",
            "\n",
            "At iteration 200 the loss is 0.693.\n",
            "At iteration 400 the loss is 0.694.\n",
            "At iteration 600 the loss is 0.693.\n",
            "At iteration 800 the loss is 0.693.\n",
            "At iteration 1000 the loss is 0.693.\n",
            "At iteration 1200 the loss is 0.693.\n",
            "At iteration 1400 the loss is 0.694.\n",
            "At iteration 1600 the loss is 0.693.\n",
            "At iteration 1800 the loss is 0.693.\n",
            "At iteration 2000 the loss is 0.693.\n",
            "\n",
            "After epoch 3 the validation accuracy is 41.667.\n",
            "\n",
            "At iteration 200 the loss is 0.693.\n",
            "At iteration 400 the loss is 0.693.\n",
            "At iteration 600 the loss is 0.692.\n",
            "At iteration 800 the loss is 0.694.\n",
            "At iteration 1000 the loss is 0.693.\n",
            "At iteration 1200 the loss is 0.693.\n",
            "At iteration 1400 the loss is 0.694.\n",
            "At iteration 1600 the loss is 0.693.\n",
            "At iteration 1800 the loss is 0.693.\n",
            "At iteration 2000 the loss is 0.693.\n",
            "\n",
            "After epoch 4 the validation accuracy is 41.667.\n",
            "\n",
            "At iteration 200 the loss is 0.693.\n",
            "At iteration 400 the loss is 0.693.\n",
            "At iteration 600 the loss is 0.692.\n",
            "At iteration 800 the loss is 0.693.\n",
            "At iteration 1000 the loss is 0.693.\n",
            "At iteration 1200 the loss is 0.693.\n",
            "At iteration 1400 the loss is 0.695.\n",
            "At iteration 1600 the loss is 0.693.\n",
            "At iteration 1800 the loss is 0.693.\n",
            "At iteration 2000 the loss is 0.693.\n",
            "\n",
            "After epoch 5 the validation accuracy is 41.667.\n",
            "\n",
            "At iteration 200 the loss is 0.693.\n",
            "At iteration 400 the loss is 0.694.\n",
            "At iteration 600 the loss is 0.693.\n",
            "At iteration 800 the loss is 0.693.\n",
            "At iteration 1000 the loss is 0.693.\n",
            "At iteration 1200 the loss is 0.693.\n",
            "At iteration 1400 the loss is 0.694.\n",
            "At iteration 1600 the loss is 0.693.\n",
            "At iteration 1800 the loss is 0.693.\n",
            "At iteration 2000 the loss is 0.693.\n",
            "\n",
            "After epoch 6 the validation accuracy is 41.667.\n",
            "\n",
            "At iteration 200 the loss is 0.693.\n",
            "At iteration 400 the loss is 0.694.\n",
            "At iteration 600 the loss is 0.693.\n",
            "At iteration 800 the loss is 0.693.\n",
            "At iteration 1000 the loss is 0.693.\n",
            "At iteration 1200 the loss is 0.693.\n",
            "At iteration 1400 the loss is 0.694.\n",
            "At iteration 1600 the loss is 0.693.\n",
            "At iteration 1800 the loss is 0.693.\n",
            "At iteration 2000 the loss is 0.693.\n",
            "\n",
            "After epoch 7 the validation accuracy is 41.667.\n",
            "\n",
            "At iteration 200 the loss is 0.693.\n",
            "At iteration 400 the loss is 0.693.\n",
            "At iteration 600 the loss is 0.693.\n",
            "At iteration 800 the loss is 0.694.\n",
            "At iteration 1000 the loss is 0.693.\n",
            "At iteration 1200 the loss is 0.693.\n",
            "At iteration 1400 the loss is 0.693.\n",
            "At iteration 1600 the loss is 0.693.\n",
            "At iteration 1800 the loss is 0.693.\n",
            "At iteration 2000 the loss is 0.693.\n",
            "\n",
            "After epoch 8 the validation accuracy is 41.667.\n",
            "\n",
            "At iteration 200 the loss is 0.693.\n",
            "At iteration 400 the loss is 0.693.\n",
            "At iteration 600 the loss is 0.693.\n",
            "At iteration 800 the loss is 0.693.\n",
            "At iteration 1000 the loss is 0.693.\n",
            "At iteration 1200 the loss is 0.693.\n",
            "At iteration 1400 the loss is 0.694.\n",
            "At iteration 1600 the loss is 0.693.\n",
            "At iteration 1800 the loss is 0.693.\n",
            "At iteration 2000 the loss is 0.693.\n",
            "\n",
            "After epoch 9 the validation accuracy is 41.667.\n",
            "\n",
            "At iteration 200 the loss is 0.693.\n",
            "At iteration 400 the loss is 0.694.\n",
            "At iteration 600 the loss is 0.693.\n",
            "At iteration 800 the loss is 0.693.\n",
            "At iteration 1000 the loss is 0.693.\n",
            "At iteration 1200 the loss is 0.693.\n",
            "At iteration 1400 the loss is 0.694.\n",
            "At iteration 1600 the loss is 0.693.\n",
            "At iteration 1800 the loss is 0.693.\n",
            "At iteration 2000 the loss is 0.693.\n",
            "\n",
            "After epoch 10 the validation accuracy is 41.667.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f944332de10>]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Glove NLTK"
      ],
      "metadata": {
        "id": "tDkwsoNzt5aX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install torchtext==0.12.0\n",
        "from torchtext.vocab import vocab as v"
      ],
      "metadata": {
        "id": "b22CIl3bt4R1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext import vocab\n",
        "\n",
        "glove = vocab.GloVe('6B')"
      ],
      "metadata": {
        "id": "evv1kTZnuQLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bow_classifier2(data):\n",
        "    counter = Counter()\n",
        "    for (line, label) in data:\n",
        "        counter.update(line)\n",
        "    vocab = v(counter, specials = ['<unk>'], special_first = True, min_freq = 1000)\n",
        "    return vocab, counter"
      ],
      "metadata": {
        "id": "YIFbYMzG0MHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_words, counter = bow_classifier2(depression_data.all_data)"
      ],
      "metadata": {
        "id": "jEC_nbO6ua_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_words.set_default_index(0)"
      ],
      "metadata": {
        "id": "QXvtlddf2YcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove_vector = glove.get_vecs_by_tokens(vocab_words.get_itos())"
      ],
      "metadata": {
        "id": "q9_3eEg50aN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    vectors = torch.zeros(len(batch), len(vocab_words))\n",
        "    label_mapping = {'non-suicide': 0, 'suicide': 1}\n",
        "    labels = []\n",
        "    for index, example in enumerate(batch):\n",
        "      indexes = vocab_words(example[0])\n",
        "      for w_idx in indexes:\n",
        "        vectors[index, int(w_idx)] = 1\n",
        "      labels.append(label_mapping.get(example[1]))\n",
        "    labels = torch.tensor(labels)\n",
        "    return  labels.cuda(),vectors.cuda()"
      ],
      "metadata": {
        "id": "LO1Hs3PXuqbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(depression_data.train, batch_size=BATCH_SIZE,\n",
        "                              shuffle=True, \n",
        "                              collate_fn=collate_fn)\n",
        "val_dataloader = DataLoader(depression_data.val, batch_size=BATCH_SIZE,\n",
        "                              shuffle=False, \n",
        "                              collate_fn=collate_fn)\n",
        "test_dataloader = DataLoader(depression_data.test, batch_size=BATCH_SIZE,\n",
        "                             shuffle=False, \n",
        "                             collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "bk_vzg6924Cr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "EPOCHS = 5\n",
        "torch.cuda.empty_cache()\n",
        "model = RNNDepressionClassifier(vocab_size = 2142,\n",
        "                                    num_classes = 2, \n",
        "                                    embedding_dim = 300, \n",
        "                                    hidden_size = 100, \n",
        "                                    num_layers = 2,\n",
        "                                use_glove = glove_vector,\n",
        "                                freeze_glove = False)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_function = nn.NLLLoss()\n",
        "if using_GPU:\n",
        "    model.cuda()\n",
        "    loss_function.to('cuda')\n",
        "accuracies=[]\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train_an_epoch(dataloader = train_dataloader,\n",
        "                    model = model,\n",
        "                    optimizer = optimizer, \n",
        "                    loss_fn=loss_function,\n",
        "                    using_GPU = using_GPU)\n",
        "    accuracy = get_accuracy(val_dataloader, model)\n",
        "    if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            with open(\"/content/drive/MyDrive/Repos/DepressionDetection/output/biLSTM_glove_best.pt\", 'wb') as f:\n",
        "                torch.save(model, f)\n",
        "                print(\"New best model saved!\")\n",
        "    \n",
        "    accuracies.append(accuracy)\n",
        "    print()\n",
        "    print(f'After epoch {epoch} the validation accuracy is {accuracy:.3f}.')\n",
        "    print()\n",
        "    \n",
        "plt.plot(range(1, EPOCHS+1), accuracies)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b6kSqYhi3CDV",
        "outputId": "7a53800f-711b-4933-f251-058eaf83ffa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "At iteration 200 the loss is 0.536.\n",
            "At iteration 400 the loss is 0.551.\n",
            "At iteration 600 the loss is 0.431.\n",
            "At iteration 800 the loss is 0.515.\n",
            "At iteration 1000 the loss is 0.449.\n",
            "At iteration 1200 the loss is 0.567.\n",
            "At iteration 1400 the loss is 0.395.\n",
            "At iteration 1600 the loss is 0.485.\n",
            "At iteration 1800 the loss is 0.659.\n",
            "At iteration 2000 the loss is 0.509.\n",
            "New best model saved!\n",
            "\n",
            "After epoch 1 the validation accuracy is 66.667.\n",
            "\n",
            "At iteration 200 the loss is 0.457.\n",
            "At iteration 400 the loss is 0.478.\n",
            "At iteration 600 the loss is 0.517.\n",
            "At iteration 800 the loss is 0.413.\n",
            "At iteration 1000 the loss is 0.556.\n",
            "At iteration 1200 the loss is 0.478.\n",
            "At iteration 1400 the loss is 0.526.\n",
            "At iteration 1600 the loss is 0.441.\n",
            "At iteration 1800 the loss is 0.456.\n",
            "At iteration 2000 the loss is 0.493.\n",
            "\n",
            "After epoch 2 the validation accuracy is 66.667.\n",
            "\n",
            "At iteration 200 the loss is 0.564.\n",
            "At iteration 400 the loss is 0.513.\n",
            "At iteration 600 the loss is 0.513.\n",
            "At iteration 800 the loss is 0.547.\n",
            "At iteration 1000 the loss is 0.412.\n",
            "At iteration 1200 the loss is 0.411.\n",
            "At iteration 1400 the loss is 0.439.\n",
            "At iteration 1600 the loss is 0.415.\n",
            "At iteration 1800 the loss is 0.496.\n",
            "At iteration 2000 the loss is 0.440.\n",
            "\n",
            "After epoch 3 the validation accuracy is 58.333.\n",
            "\n",
            "At iteration 200 the loss is 0.582.\n",
            "At iteration 400 the loss is 0.586.\n",
            "At iteration 600 the loss is 0.508.\n",
            "At iteration 800 the loss is 0.351.\n",
            "At iteration 1000 the loss is 0.530.\n",
            "At iteration 1200 the loss is 0.503.\n",
            "At iteration 1400 the loss is 0.493.\n",
            "At iteration 1600 the loss is 0.418.\n",
            "At iteration 1800 the loss is 0.445.\n",
            "At iteration 2000 the loss is 0.577.\n",
            "New best model saved!\n",
            "\n",
            "After epoch 4 the validation accuracy is 75.000.\n",
            "\n",
            "At iteration 200 the loss is 0.483.\n",
            "At iteration 400 the loss is 0.528.\n",
            "At iteration 600 the loss is 0.462.\n",
            "At iteration 800 the loss is 0.457.\n",
            "At iteration 1000 the loss is 0.578.\n",
            "At iteration 1200 the loss is 0.421.\n",
            "At iteration 1400 the loss is 0.432.\n",
            "At iteration 1600 the loss is 0.462.\n",
            "At iteration 1800 the loss is 0.523.\n",
            "At iteration 2000 the loss is 0.449.\n",
            "\n",
            "After epoch 5 the validation accuracy is 58.333.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f9440872250>]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Glove Split"
      ],
      "metadata": {
        "id": "vdXXYJs9EMEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "depression_data = dep_data(data_dir, tokenizer = \"split\")\n",
        "depression_data.split_data(123)\n"
      ],
      "metadata": {
        "id": "7FFuxFH4l7CX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39656d5f-1985-4396-861a-da0e439e33b3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  result = getattr(asarray(obj), method)(*args, **kwds)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext import vocab\n",
        "\n",
        "glove = vocab.GloVe('6B')"
      ],
      "metadata": {
        "id": "K12smhvBESHq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bow_classifier2(data):\n",
        "    counter = Counter()\n",
        "    for (line, label) in data:\n",
        "        counter.update(line)\n",
        "    vocab = v(counter, specials = ['<unk>'], special_first = True, min_freq = 1000)\n",
        "    return vocab, counter"
      ],
      "metadata": {
        "id": "2Rtdfb-vEXFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_words, counter = bow_classifier2(depression_data.all_data)"
      ],
      "metadata": {
        "id": "F0nbmUxPEYbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_words.set_default_index(0)"
      ],
      "metadata": {
        "id": "x6UXykDuEae-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove_vector = glove.get_vecs_by_tokens(vocab_words.get_itos())"
      ],
      "metadata": {
        "id": "mbQ9_QDKEcHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    vectors = torch.zeros(len(batch), len(vocab_words))\n",
        "    label_mapping = {'non-suicide': 0, 'suicide': 1}\n",
        "    labels = []\n",
        "    for index, example in enumerate(batch):\n",
        "      indexes = vocab_words(example[0])\n",
        "      for w_idx in indexes:\n",
        "        vectors[index, int(w_idx)] = 1\n",
        "      labels.append(label_mapping.get(example[1]))\n",
        "    labels = torch.tensor(labels)\n",
        "    return  labels.cuda(),vectors.cuda()"
      ],
      "metadata": {
        "id": "ZCgYZ13AEdY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(depression_data.train, batch_size=BATCH_SIZE,\n",
        "                              shuffle=True, \n",
        "                              collate_fn=collate_fn)\n",
        "val_dataloader = DataLoader(depression_data.val, batch_size=BATCH_SIZE,\n",
        "                              shuffle=False, \n",
        "                              collate_fn=collate_fn)\n",
        "test_dataloader = DataLoader(depression_data.test, batch_size=BATCH_SIZE,\n",
        "                             shuffle=False, \n",
        "                             collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "F9RdnZzSEgNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "EPOCHS = 5\n",
        "torch.cuda.empty_cache()\n",
        "model = RNNDepressionClassifier(vocab_size = 2142,\n",
        "                                    num_classes = 2, \n",
        "                                    embedding_dim = 300, \n",
        "                                    hidden_size = 100, \n",
        "                                    num_layers = 2,\n",
        "                                use_glove = glove_vector,\n",
        "                                freeze_glove = False)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_function = nn.NLLLoss()\n",
        "if using_GPU:\n",
        "    model.cuda()\n",
        "    loss_function.to('cuda')\n",
        "accuracies=[]\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train_an_epoch(dataloader = train_dataloader,\n",
        "                    model = model,\n",
        "                    optimizer = optimizer, \n",
        "                    loss_fn=loss_function,\n",
        "                    using_GPU = using_GPU)\n",
        "    accuracy = get_accuracy(val_dataloader, model)\n",
        "    if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            with open(\"/content/drive/MyDrive/Repos/DepressionDetection/output/biLSTM_glove_best_split.pt\", 'wb') as f:\n",
        "                torch.save(model, f)\n",
        "                print(\"New best model saved!\")\n",
        "    \n",
        "    accuracies.append(accuracy)\n",
        "    print()\n",
        "    print(f'After epoch {epoch} the validation accuracy is {accuracy:.3f}.')\n",
        "    print()\n",
        "    \n",
        "plt.plot(range(1, EPOCHS+1), accuracies)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RJd_WffYEhgd",
        "outputId": "7081f0ff-de6a-4b37-d2ee-7a83d3d3e0e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "At iteration 200 the loss is 0.555.\n",
            "At iteration 400 the loss is 0.478.\n",
            "At iteration 600 the loss is 0.460.\n",
            "At iteration 800 the loss is 0.522.\n",
            "At iteration 1000 the loss is 0.608.\n",
            "At iteration 1200 the loss is 0.443.\n",
            "At iteration 1400 the loss is 0.545.\n",
            "At iteration 1600 the loss is 0.395.\n",
            "At iteration 1800 the loss is 0.565.\n",
            "At iteration 2000 the loss is 0.452.\n",
            "\n",
            "After epoch 1 the validation accuracy is 66.667.\n",
            "\n",
            "At iteration 200 the loss is 0.620.\n",
            "At iteration 400 the loss is 0.546.\n",
            "At iteration 600 the loss is 0.462.\n",
            "At iteration 800 the loss is 0.581.\n",
            "At iteration 1000 the loss is 0.480.\n",
            "At iteration 1200 the loss is 0.427.\n",
            "At iteration 1400 the loss is 0.514.\n",
            "At iteration 1600 the loss is 0.494.\n",
            "At iteration 1800 the loss is 0.503.\n",
            "At iteration 2000 the loss is 0.478.\n",
            "\n",
            "After epoch 2 the validation accuracy is 66.667.\n",
            "\n",
            "At iteration 200 the loss is 0.410.\n",
            "At iteration 400 the loss is 0.477.\n",
            "At iteration 600 the loss is 0.605.\n",
            "At iteration 800 the loss is 0.527.\n",
            "At iteration 1000 the loss is 0.588.\n",
            "At iteration 1200 the loss is 0.501.\n",
            "At iteration 1400 the loss is 0.545.\n",
            "At iteration 1600 the loss is 0.457.\n",
            "At iteration 1800 the loss is 0.614.\n",
            "At iteration 2000 the loss is 0.446.\n",
            "\n",
            "After epoch 3 the validation accuracy is 66.667.\n",
            "\n",
            "At iteration 200 the loss is 0.478.\n",
            "At iteration 400 the loss is 0.426.\n",
            "At iteration 600 the loss is 0.579.\n",
            "At iteration 800 the loss is 0.551.\n",
            "At iteration 1000 the loss is 0.561.\n",
            "At iteration 1200 the loss is 0.461.\n",
            "At iteration 1400 the loss is 0.491.\n",
            "At iteration 1600 the loss is 0.507.\n",
            "At iteration 1800 the loss is 0.443.\n",
            "At iteration 2000 the loss is 0.482.\n",
            "\n",
            "After epoch 4 the validation accuracy is 66.667.\n",
            "\n",
            "At iteration 200 the loss is 0.562.\n",
            "At iteration 400 the loss is 0.455.\n",
            "At iteration 600 the loss is 0.578.\n",
            "At iteration 800 the loss is 0.500.\n",
            "At iteration 1000 the loss is 0.497.\n",
            "At iteration 1200 the loss is 0.568.\n",
            "At iteration 1400 the loss is 0.309.\n",
            "At iteration 1600 the loss is 0.620.\n",
            "At iteration 1800 the loss is 0.417.\n",
            "At iteration 2000 the loss is 0.525.\n",
            "\n",
            "After epoch 5 the validation accuracy is 66.667.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f9443625050>]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TF - IDF"
      ],
      "metadata": {
        "id": "I3_AjWf7TFQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn_tfidf(batch):\n",
        "  tf_idf_matrix = torch.zeros(len(batch), tf_idf.shape[1])\n",
        "  labels = []\n",
        "  for i, (index, text, label) in enumerate(batch):\n",
        "    tf_idf_matrix[i] = tf_idf[index]\n",
        "    labels.append(label)\n",
        "  return torch.tensor(labels).to(\"cuda\"), tf_idf_matrix.to(\"cuda\")"
      ],
      "metadata": {
        "id": "sxeKKGQGElsm"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "depression_data = dep_data(data_dir, pandas = True)"
      ],
      "metadata": {
        "id": "Z113M5zgTGwi"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "depression_data.split_data(123, pandas = True)"
      ],
      "metadata": {
        "id": "p5rJ7crVTH69"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf_idf, labels = create_tf_idf(depression_data.all_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0YS3Iz9TJNV",
        "outputId": "f8aec555-fc60-4291-88bf-6d6a06e6f1e1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "depression_data.train[\"class\"] = depression_data.train[\"class\"].map(LABEL_MAPPINGS)\n",
        "depression_data.val[\"class\"] = depression_data.val[\"class\"].map(LABEL_MAPPINGS)"
      ],
      "metadata": {
        "id": "-IEzNvkwTK7I"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(depression_data.train.values.tolist(), batch_size=64,\n",
        "                              shuffle=True, \n",
        "                              collate_fn=collate_fn_tfidf)\n",
        "val_dataloader = DataLoader(depression_data.val.values.tolist(), batch_size=64,\n",
        "                              shuffle=True, \n",
        "                              collate_fn=collate_fn_tfidf)"
      ],
      "metadata": {
        "id": "ZbAtGGnuTMNz"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "EPOCHS = 5\n",
        "using_GPU = True\n",
        "torch.cuda.empty_cache()\n",
        "model = RNNDepressionClassifier(vocab_size = len(tf_idf),\n",
        "                                    num_classes = 2, \n",
        "                                    embedding_dim = 300, \n",
        "                                    hidden_size = 100, \n",
        "                                    num_layers = 2,\n",
        "                                use_glove = None,\n",
        "                                freeze_glove = False)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_function = nn.NLLLoss()\n",
        "best_accuracy = 0\n",
        "if using_GPU:\n",
        "    model.cuda()\n",
        "    loss_function.to('cuda')\n",
        "accuracies=[]\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train_an_epoch(dataloader = train_dataloader,\n",
        "                    model = model,\n",
        "                    optimizer = optimizer, \n",
        "                    loss_fn=loss_function,\n",
        "                    using_GPU = using_GPU)\n",
        "    accuracy = get_accuracy(val_dataloader, model)\n",
        "    if accuracy > best_accuracy:\n",
        "      best_accuracy = accuracy\n",
        "      with open(\"/content/drive/MyDrive/Repos/DepressionDetection/output/biLSTM_tf_idf_best.pt\", 'wb') as f:\n",
        "          torch.save(model, f)\n",
        "          print(\"New best model saved!\")\n",
        "    \n",
        "    accuracies.append(accuracy)\n",
        "    print()\n",
        "    print(f'After epoch {epoch} the validation accuracy is {accuracy:.3f}.')\n",
        "    print()\n",
        "    \n",
        "plt.plot(range(1, EPOCHS+1), accuracies)"
      ],
      "metadata": {
        "id": "x6gSETMpTNVD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8a925943-a507-40bd-b639-af557f2e9117"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "At iteration 200 the loss is 0.694.\n",
            "At iteration 400 the loss is 0.691.\n",
            "At iteration 600 the loss is 0.693.\n",
            "At iteration 800 the loss is 0.691.\n",
            "At iteration 1000 the loss is 0.696.\n",
            "At iteration 1200 the loss is 0.693.\n",
            "At iteration 1400 the loss is 0.697.\n",
            "At iteration 1600 the loss is 0.693.\n",
            "At iteration 1800 the loss is 0.691.\n",
            "At iteration 2000 the loss is 0.672.\n",
            "At iteration 2200 the loss is 0.684.\n",
            "New best model saved!\n",
            "\n",
            "After epoch 1 the validation accuracy is 50.000.\n",
            "\n",
            "At iteration 200 the loss is 0.682.\n",
            "At iteration 400 the loss is 0.693.\n",
            "At iteration 600 the loss is 0.678.\n",
            "At iteration 800 the loss is 0.695.\n",
            "At iteration 1000 the loss is 0.686.\n",
            "At iteration 1200 the loss is 0.706.\n",
            "At iteration 1400 the loss is 0.687.\n",
            "At iteration 1600 the loss is 0.693.\n",
            "At iteration 1800 the loss is 0.692.\n",
            "At iteration 2000 the loss is 0.693.\n",
            "At iteration 2200 the loss is 0.694.\n",
            "New best model saved!\n",
            "\n",
            "After epoch 2 the validation accuracy is 58.333.\n",
            "\n",
            "At iteration 200 the loss is 0.698.\n",
            "At iteration 400 the loss is 0.692.\n",
            "At iteration 600 the loss is 0.687.\n",
            "At iteration 800 the loss is 0.701.\n",
            "At iteration 1000 the loss is 0.693.\n",
            "At iteration 1200 the loss is 0.684.\n",
            "At iteration 1400 the loss is 0.687.\n",
            "At iteration 1600 the loss is 0.694.\n",
            "At iteration 1800 the loss is 0.707.\n",
            "At iteration 2000 the loss is 0.695.\n",
            "At iteration 2200 the loss is 0.680.\n",
            "\n",
            "After epoch 3 the validation accuracy is 58.333.\n",
            "\n",
            "At iteration 200 the loss is 0.693.\n",
            "At iteration 400 the loss is 0.714.\n",
            "At iteration 600 the loss is 0.685.\n",
            "At iteration 800 the loss is 0.688.\n",
            "At iteration 1000 the loss is 0.692.\n",
            "At iteration 1200 the loss is 0.693.\n",
            "At iteration 1400 the loss is 0.692.\n",
            "At iteration 1600 the loss is 0.690.\n",
            "At iteration 1800 the loss is 0.700.\n",
            "At iteration 2000 the loss is 0.686.\n",
            "At iteration 2200 the loss is 0.682.\n",
            "\n",
            "After epoch 4 the validation accuracy is 41.667.\n",
            "\n",
            "At iteration 200 the loss is 0.685.\n",
            "At iteration 400 the loss is 0.694.\n",
            "At iteration 600 the loss is 0.686.\n",
            "At iteration 800 the loss is 0.685.\n",
            "At iteration 1000 the loss is 0.685.\n",
            "At iteration 1200 the loss is 0.685.\n",
            "At iteration 1400 the loss is 0.712.\n",
            "At iteration 1600 the loss is 0.705.\n",
            "At iteration 1800 the loss is 0.686.\n",
            "At iteration 2000 the loss is 0.712.\n",
            "At iteration 2200 the loss is 0.692.\n",
            "\n",
            "After epoch 5 the validation accuracy is 25.000.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f2a3a214dd0>]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Q8x0SQ-Gk6tP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}